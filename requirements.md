# PRD of the web crawler

## Functionalities

1. a command line tool used to craw web pages
2. user provides a json config file
    1. cookies for login state auth
    2. startUrls for pages to be crawled
    3. excludeUrls for pages not to be crawled
    4. depth for embeded urls
    5. maxCount for max crawled pages count
    6. output for local file dir
3. crawl the web page (including style, images, content) and save them as pdf format file to local dir. the generated pdf files keep the original web page style & images.
4. the pdf file name format is generated by page title for meaningfulness and a suffix id for uniqueness
5. crawl nested link as well, but don't crawl pages that are not the same host as the startUrl
6. for url equality, use the host, path & configured params to compare. param name order doesn't matter.
7. use fonts that support Chinese chars

## Tech Constraints

1. user java 21, spring boot 3.5.6
2. generate a shell script to run easily
3. it's better to use the PlayWright framework
